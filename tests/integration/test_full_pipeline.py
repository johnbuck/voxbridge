"""
Integration tests for full audio pipeline

Tests complete workflows:
- Audio ‚Üí WhisperX ‚Üí Transcript ‚Üí n8n ‚Üí LLM ‚Üí TTS ‚Üí Playback
- Speaker lock management in multi-user scenarios
- Error recovery and reconnection
- Silence detection and timeout enforcement

LATENCY TARGETS:
- Audio to transcript: <500ms
- Transcript to TTS start: <200ms
- Total end-to-end: <2000ms
"""
from __future__ import annotations

import pytest
import asyncio
from unittest.mock import MagicMock, AsyncMock, patch
import time

from src.speaker_manager import SpeakerManager
from src.streaming_handler import StreamingResponseHandler
from src.whisper_client import WhisperClient


# ============================================================
# Full Audio-to-Playback Pipeline Tests
# ============================================================

@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_full_audio_to_transcript_pipeline(
    mock_whisperx_server,
    latency_tracker,
    latency_assertions
):
    """
    Test: Audio chunks ‚Üí WhisperX ‚Üí Transcript

    VALIDATES:
    - Audio streaming to WhisperX
    - Partial transcripts received
    - Final transcript received
    - Total latency < 500ms
    """
    # Create WhisperClient (will use mock server)
    client = WhisperClient()

    # Track transcripts
    partial_transcripts = []
    final_transcript = None

    async def on_partial(text):
        partial_transcripts.append(text)

    async def on_final(text):
        nonlocal final_transcript
        final_transcript = text

    client.on_partial_callback = on_partial
    client.on_final_callback = on_final

    latency_tracker.start("audio_to_transcript")

    # Realistic WebSocket mocking
    mock_ws = AsyncMock()
    mock_ws.send = AsyncMock()
    mock_ws.close = AsyncMock()

    # Mock the async iterator for receiving messages
    async def mock_messages():
        # Simulate realistic WhisperX behavior
        await asyncio.sleep(0.05)  # 50ms processing delay
        yield '{"type": "partial", "text": "Hello this is"}'
        await asyncio.sleep(0.05)  # Another 50ms
        yield '{"type": "final", "text": "Hello this is a test"}'

    mock_ws.__aiter__ = lambda self: mock_messages()

    with patch('websockets.connect') as mock_connect:
        async def connect_mock(*args, **kwargs):
            return mock_ws

        mock_connect.side_effect = connect_mock

        await client.connect("user_123")

        # Verify start message was sent
        assert mock_ws.send.called
        start_call = mock_ws.send.call_args_list[0][0][0]
        assert 'type' in start_call and 'start' in start_call

        # Send audio chunks (realistic timing)
        for i in range(5):
            audio_chunk = b'\x00' * 960  # Opus packet
            await client.send_audio(audio_chunk)
            await asyncio.sleep(0.01)  # Simulate 10ms real-time audio

        # Simulate partial transcript arriving
        await asyncio.sleep(0.05)  # 50ms transcription delay
        await client._handle_message('{"type": "partial", "text": "Hello this is"}')

        # Simulate final transcript arriving
        await asyncio.sleep(0.05)  # Another 50ms
        await client._handle_message('{"type": "final", "text": "Hello this is a test"}')

    latency = latency_tracker.end("audio_to_transcript")

    print(f"\nüéØ Audio ‚Üí Transcript: {latency:.2f}ms")
    print(f"   Partial transcripts: {partial_transcripts}")
    print(f"   Final transcript: {final_transcript}")
    print(f"   Audio chunks sent: 5")
    print(f"   Total latency: {latency:.2f}ms (target: <500ms)")

    # ASSERTIONS
    latency_assertions.assert_low_latency(latency, 500, "Audio to transcript")
    assert final_transcript == "Hello this is a test"
    assert len(partial_transcripts) >= 1
    assert partial_transcripts[0] == "Hello this is"


@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_transcript_to_tts_pipeline(
    mock_n8n_server,
    mock_chatterbox_server,
    speaker_manager_with_mocks,
    latency_tracker,
    latency_assertions
):
    """
    Test: Transcript ‚Üí n8n webhook ‚Üí LLM response ‚Üí TTS streaming

    VALIDATES:
    - Transcript sent to n8n
    - Streaming response received
    - TTS synthesis triggered
    - Total latency < 1000ms
    """
    manager = speaker_manager_with_mocks
    manager.n8n_webhook_url = mock_n8n_server["webhook_url"]
    manager.use_streaming = True

    # Track chunks received
    chunks_received = []

    # Create realistic streaming handler mock
    mock_handler = MagicMock()

    async def mock_on_chunk(chunk_text):
        chunks_received.append(chunk_text)

    mock_handler.on_chunk = mock_on_chunk
    mock_handler.finalize = AsyncMock()
    manager.streaming_handler = mock_handler

    latency_tracker.start("transcript_to_tts")

    # Realistic HTTP SSE streaming response
    with patch('httpx.AsyncClient') as MockClient:
        mock_http_client = MagicMock()

        # Mock streaming POST response with SSE chunks
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.raise_for_status = MagicMock()

        # Simulate realistic SSE streaming (incremental LLM response)
        async def mock_aiter_lines():
            # Simulate realistic n8n SSE format with delays
            await asyncio.sleep(0.05)  # 50ms LLM first token latency
            yield 'data: {"text": "I\'m doing"}'
            await asyncio.sleep(0.02)  # 20ms between tokens
            yield 'data: {"text": " great,"}'
            await asyncio.sleep(0.02)
            yield 'data: {"text": " thank"}'
            await asyncio.sleep(0.02)
            yield 'data: {"text": " you!"}'
            await asyncio.sleep(0.01)
            yield 'data: [DONE]'

        mock_response.aiter_lines = mock_aiter_lines

        # Mock the stream context manager
        mock_stream_ctx = MagicMock()
        mock_stream_ctx.__aenter__ = AsyncMock(return_value=mock_response)
        mock_stream_ctx.__aexit__ = AsyncMock(return_value=None)
        mock_http_client.stream = MagicMock(return_value=mock_stream_ctx)

        MockClient.return_value.__aenter__ = AsyncMock(return_value=mock_http_client)
        MockClient.return_value.__aexit__ = AsyncMock(return_value=None)

        manager.active_speaker = "user_123"

        # Mock the streaming response handler
        with patch.object(manager, '_handle_streaming_response', new_callable=AsyncMock) as mock_streaming:
            await manager._send_to_n8n("Hello, how are you?")

    latency = latency_tracker.end("transcript_to_tts")

    print(f"\nüéØ Transcript ‚Üí TTS start: {latency:.2f}ms")
    print(f"   _handle_streaming_response called: {mock_streaming.called}")
    print(f"   Total latency: {latency:.2f}ms (target: <1000ms)")

    # ASSERTIONS
    latency_assertions.assert_low_latency(latency, 1000, "Transcript to TTS")
    # Verify streaming handler was called (since use_streaming=True)
    assert mock_streaming.called, "Streaming response handler should be called"


@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_end_to_end_conversation_loop(
    mock_whisperx_server,
    mock_n8n_server,
    mock_chatterbox_server,
    latency_tracker,
    latency_assertions
):
    """
    Test: Complete conversation loop
    User speaks ‚Üí Transcribed ‚Üí LLM responds ‚Üí Bot speaks back

    VALIDATES:
    - All components work together
    - Total latency < 2000ms
    - Streaming works end-to-end
    """
    # Initialize all components
    speaker_manager = SpeakerManager()
    speaker_manager.n8n_webhook_url = mock_n8n_server["webhook_url"]
    speaker_manager.use_streaming = True

    mock_voice_client = MagicMock()
    mock_voice_client.is_connected.return_value = True
    mock_voice_client.is_playing.return_value = False

    speaker_manager.set_voice_connection(mock_voice_client)

    latency_tracker.start("full_conversation")

    # ============================================================
    # Stage 1: User speaks (audio ‚Üí transcript)
    # ============================================================
    latency_tracker.start("stage_1_transcription")

    whisper_client = WhisperClient()

    # Realistic WhisperX WebSocket mocking
    mock_ws = AsyncMock()
    mock_ws.send = AsyncMock()
    mock_ws.close = AsyncMock()

    async def mock_connect(*args, **kwargs):
        return mock_ws

    with patch('websockets.connect', side_effect=mock_connect):
        await whisper_client.connect("user_123")

        # Send audio chunks with realistic timing
        for _ in range(3):
            await whisper_client.send_audio(b'\x00' * 960)
            await asyncio.sleep(0.02)  # 20ms real-time audio

        # Simulate WhisperX transcription (realistic delays)
        await asyncio.sleep(0.05)  # 50ms processing
        await whisper_client._handle_message('{"type": "partial", "text": "What is"}')
        await asyncio.sleep(0.05)
        await whisper_client._handle_message('{"type": "final", "text": "What is the weather?"}')

        transcript = whisper_client.get_transcript()

    latency_tracker.end("stage_1_transcription")

    # ============================================================
    # Stage 2: Send to n8n and get LLM response
    # ============================================================
    latency_tracker.start("stage_2_llm_response")

    speaker_manager.active_speaker = "user_123"

    # Realistic n8n SSE streaming mocking
    with patch('httpx.AsyncClient') as MockClient:
        mock_http_client = MagicMock()

        # Mock SSE streaming response
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.raise_for_status = MagicMock()

        async def mock_aiter_lines():
            await asyncio.sleep(0.1)  # 100ms LLM first token
            yield 'data: {"text": "The weather"}'
            await asyncio.sleep(0.02)
            yield 'data: {"text": " is sunny"}'
            await asyncio.sleep(0.02)
            yield 'data: {"text": " and 75 degrees."}'
            yield 'data: [DONE]'

        mock_response.aiter_lines = mock_aiter_lines

        mock_stream_ctx = MagicMock()
        mock_stream_ctx.__aenter__ = AsyncMock(return_value=mock_response)
        mock_stream_ctx.__aexit__ = AsyncMock(return_value=None)
        mock_http_client.stream = MagicMock(return_value=mock_stream_ctx)

        MockClient.return_value.__aenter__ = AsyncMock(return_value=mock_http_client)
        MockClient.return_value.__aexit__ = AsyncMock(return_value=None)

        with patch.object(speaker_manager, '_handle_streaming_response', new_callable=AsyncMock):
            await speaker_manager._send_to_n8n(transcript)

    latency_tracker.end("stage_2_llm_response")

    # ============================================================
    # Stage 3: TTS and playback
    # ============================================================
    latency_tracker.start("stage_3_tts_playback")

    handler = StreamingResponseHandler(mock_voice_client, "user_123")
    handler.chatterbox_url = mock_chatterbox_server["base_url"]

    # Realistic Chatterbox TTS HTTP streaming mocking
    with patch('httpx.AsyncClient') as MockTTSClient:
        mock_tts_client = MagicMock()

        # Mock TTS streaming response
        mock_tts_response = AsyncMock()
        mock_tts_response.raise_for_status = MagicMock()

        async def mock_aiter_bytes(chunk_size):
            # Simulate realistic TTS streaming (5 chunks)
            await asyncio.sleep(0.02)  # 20ms first chunk
            for i in range(5):
                await asyncio.sleep(0.01)  # 10ms between chunks
                yield b'\x00' * 1024

        mock_tts_response.aiter_bytes = mock_aiter_bytes

        mock_tts_stream_ctx = MagicMock()
        mock_tts_stream_ctx.__aenter__ = AsyncMock(return_value=mock_tts_response)
        mock_tts_stream_ctx.__aexit__ = AsyncMock(return_value=None)
        mock_tts_client.stream = MagicMock(return_value=mock_tts_stream_ctx)

        MockTTSClient.return_value.__aenter__ = AsyncMock(return_value=mock_tts_client)
        MockTTSClient.return_value.__aexit__ = AsyncMock(return_value=None)

        with patch('tempfile.NamedTemporaryFile'):
            with patch('discord.FFmpegPCMAudio'):
                with patch('os.unlink'):
                    await handler._synthesize_and_play("The weather is sunny and 75 degrees.")

    latency_tracker.end("stage_3_tts_playback")

    total_latency = latency_tracker.end("full_conversation")

    # Print comprehensive report
    print("\n" + "=" * 60)
    print("END-TO-END CONVERSATION LOOP REPORT")
    print("=" * 60)
    print(latency_tracker.report())
    print("=" * 60)
    print(f"\nüìä Stage Breakdown:")
    print(f"   1. Audio ‚Üí Transcript:    {latency_tracker.get_average('stage_1_transcription'):.2f}ms")
    print(f"   2. Transcript ‚Üí LLM:      {latency_tracker.get_average('stage_2_llm_response'):.2f}ms")
    print(f"   3. TTS ‚Üí Playback:        {latency_tracker.get_average('stage_3_tts_playback'):.2f}ms")
    print(f"   TOTAL:                    {total_latency:.2f}ms")

    # CRITICAL ASSERTION
    latency_assertions.assert_low_latency(total_latency, 2000, "Full conversation loop")

    print(f"\n‚úÖ Complete conversation in {total_latency:.2f}ms (target: <2000ms)")


# ============================================================
# Multi-User Speaker Lock Tests
# ============================================================

@pytest.mark.integration
@pytest.mark.asyncio
async def test_speaker_lock_with_real_timing():
    """
    Test speaker lock with realistic timing

    VALIDATES:
    - First speaker acquires lock
    - Second speaker blocked
    - Lock released after silence
    - Second speaker can then speak
    """
    manager = SpeakerManager()
    manager.silence_threshold_ms = 100  # Fast for testing

    # User 1 starts speaking
    async def audio_stream_1():
        for _ in range(3):
            yield b'\x00' * 960

    with patch.object(manager, '_start_transcription', new_callable=AsyncMock):
        with patch('asyncio.create_task'):
            result1 = await manager.on_speaking_start("user_1", audio_stream_1())
            assert result1 is True
            assert manager.active_speaker == "user_1"

    # User 2 tries to speak (should be blocked)
    async def audio_stream_2():
        yield b'\x00' * 960

    result2 = await manager.on_speaking_start("user_2", audio_stream_2())
    assert result2 is False
    assert manager.active_speaker == "user_1"  # Still user 1

    # Simulate silence detection
    manager.whisper_client = AsyncMock()
    manager.whisper_client.finalize = AsyncMock(return_value="test")
    manager.whisper_client.close = AsyncMock()

    with patch('asyncio.gather', new_callable=AsyncMock):
        await manager._finalize_transcription('silence')

    assert manager.active_speaker is None  # Lock released

    # User 2 can now speak
    with patch.object(manager, '_start_transcription', new_callable=AsyncMock):
        with patch('asyncio.create_task'):
            result3 = await manager.on_speaking_start("user_2", audio_stream_2())
            assert result3 is True
            assert manager.active_speaker == "user_2"

    print("\n‚úÖ Speaker lock workflow validated")


@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_timeout_enforcement_with_real_timing():
    """
    Test timeout enforcement with realistic timing

    VALIDATES:
    - Lock released after max speaking time
    - Timeout monitoring works correctly
    - Cleanup happens properly
    """
    manager = SpeakerManager()
    manager.max_speaking_time_ms = 100  # Fast for testing

    manager.active_speaker = "user_123"
    manager.lock_start_time = time.time()

    manager.whisper_client = AsyncMock()
    manager.whisper_client.finalize = AsyncMock(return_value="test")
    manager.whisper_client.close = AsyncMock()

    # Run timeout monitor
    with patch('asyncio.gather', new_callable=AsyncMock):
        await manager._timeout_monitor()

    # Verify lock released
    assert manager.active_speaker is None

    print("\n‚úÖ Timeout enforcement validated")


# ============================================================
# Error Recovery Tests
# ============================================================

@pytest.mark.integration
@pytest.mark.asyncio
async def test_whisperx_reconnection_during_audio():
    """
    Test WhisperX reconnection during active audio streaming

    VALIDATES:
    - Connection loss detected
    - Reconnection attempted
    - Audio buffering continues
    - Transcription resumes
    """
    client = WhisperClient()

    # Realistic WebSocket mocking for initial connection
    mock_ws1 = AsyncMock()
    mock_ws1.send = AsyncMock()
    mock_ws1.close = AsyncMock()

    connection_attempts = []

    async def mock_connect_with_tracking(*args, **kwargs):
        connection_attempts.append(len(connection_attempts) + 1)
        if len(connection_attempts) == 1:
            return mock_ws1
        else:
            # Second connection (after reconnect)
            mock_ws2 = AsyncMock()
            mock_ws2.send = AsyncMock()
            mock_ws2.close = AsyncMock()
            return mock_ws2

    with patch('websockets.connect', side_effect=mock_connect_with_tracking):
        # First connection succeeds
        await client.connect("user_123", retry=False)
        assert client.is_connected
        assert len(connection_attempts) == 1

        # Verify start message was sent
        assert mock_ws1.send.called
        start_message = mock_ws1.send.call_args_list[0][0][0]
        assert '"type": "start"' in start_message
        assert '"userId": "user_123"' in start_message

        # Send some audio
        await client.send_audio(b'\x00' * 960)
        assert mock_ws1.send.call_count >= 2  # start + audio

    # Simulate connection loss (realistic scenario)
    print("\n‚ö†Ô∏è  Simulating connection loss...")
    client.is_connected = False
    client.ws = None

    # Verify audio sending fails gracefully when disconnected
    await client.send_audio(b'\xFF' * 960)  # Should log warning, not crash

    # Attempt reconnection
    print("üîÑ Reconnecting...")
    with patch('websockets.connect', side_effect=mock_connect_with_tracking):
        await client.connect("user_123", retry=False)
        assert client.is_connected
        assert len(connection_attempts) == 2  # Second connection

        # Resume audio streaming after reconnection
        await asyncio.sleep(0.01)  # Small delay (realistic)
        await client.send_audio(b'\x01' * 960)

        # Simulate receiving transcript after reconnection
        await asyncio.sleep(0.05)  # 50ms processing
        await client._handle_message('{"type": "final", "text": "Reconnected successfully"}')

        assert client.get_transcript() == "Reconnected successfully"

    print(f"\n‚úÖ WhisperX reconnection validated")
    print(f"   Connection attempts: {len(connection_attempts)}")
    print(f"   Final transcript: {client.get_transcript()}")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_n8n_retry_with_real_timing(mock_n8n_server):
    """
    Test n8n webhook retry with realistic timing

    VALIDATES:
    - Retry logic with exponential backoff
    - Success after retries
    - Timing is reasonable
    """
    import httpx

    manager = SpeakerManager()
    manager.n8n_webhook_url = mock_n8n_server["webhook_url"]
    manager.use_streaming = False
    manager.active_speaker = "user_123"

    retry_count = 0
    retry_times = []

    # Realistic HTTP mocking with retry simulation
    with patch('httpx.AsyncClient') as MockClient:
        mock_http_client = MagicMock()

        # First 2 attempts fail, 3rd succeeds (realistic retry scenario)
        async def failing_post(*args, **kwargs):
            nonlocal retry_count
            retry_count += 1
            retry_times.append(time.perf_counter())

            print(f"   Attempt {retry_count}...")

            if retry_count < 3:
                # Simulate network timeout
                await asyncio.sleep(0.01)  # Small realistic delay
                raise httpx.TimeoutException("Timeout")

            # Third attempt succeeds
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.raise_for_status = MagicMock()
            mock_response.json = AsyncMock(return_value={"status": "success"})
            return mock_response

        mock_http_client.post = failing_post

        MockClient.return_value.__aenter__ = AsyncMock(return_value=mock_http_client)
        MockClient.return_value.__aexit__ = AsyncMock(return_value=None)

        # Should succeed after retries
        print("\nüîÑ Testing n8n retry logic...")
        await manager._send_to_n8n("Test message")

    assert retry_count == 3, f"Expected 3 attempts, got {retry_count}"

    print(f"\n‚úÖ Retry logic validated: {retry_count} attempts")

    # Check exponential backoff timing
    if len(retry_times) >= 3:
        delay1 = (retry_times[1] - retry_times[0]) * 1000
        delay2 = (retry_times[2] - retry_times[1]) * 1000

        print(f"   First retry delay:  {delay1:.2f}ms")
        print(f"   Second retry delay: {delay2:.2f}ms")

        # Verify exponential backoff (second delay should be longer)
        # Allow some tolerance for timing variations
        print(f"   Exponential backoff: {'‚úÖ' if delay2 >= delay1 * 0.8 else '‚ö†Ô∏è'}")


# ============================================================
# Backpressure and Load Tests
# ============================================================

@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_rapid_audio_chunks_no_blocking(latency_tracker):
    """
    Test handling rapid audio chunks without blocking

    VALIDATES:
    - Audio buffering handles fast input
    - No blocking on processing
    - All chunks queued successfully
    """
    from discord_bot import AudioReceiver

    mock_vc = MagicMock()
    mock_speaker_mgr = MagicMock()
    mock_speaker_mgr.on_speaking_start = AsyncMock(return_value=True)

    receiver = AudioReceiver(mock_vc, mock_speaker_mgr)

    mock_user = MagicMock()
    mock_user.id = 12345

    latency_tracker.start("rapid_audio_buffering")

    with patch('asyncio.create_task'):
        # Send 100 rapid audio packets
        for i in range(100):
            audio_data = {'data': bytes([i % 256]) * 960, 'timestamp': i * 20}
            receiver.write(audio_data, mock_user)

    latency = latency_tracker.end("rapid_audio_buffering")

    print(f"\nüéØ Buffered 100 audio packets in {latency:.2f}ms")
    print(f"   Average per packet: {latency/100:.2f}ms")

    # Should be very fast (non-blocking)
    assert latency < 50, f"Audio buffering too slow: {latency:.2f}ms"
    assert receiver.user_buffers['12345'].qsize() == 100


@pytest.mark.integration
@pytest.mark.latency
@pytest.mark.asyncio
async def test_concurrent_users_no_contention(latency_tracker):
    """
    Test multiple users sending audio concurrently

    VALIDATES:
    - No resource contention
    - Each user gets isolated buffer
    - Performance doesn't degrade
    """
    from discord_bot import AudioReceiver

    mock_vc = MagicMock()
    mock_speaker_mgr = MagicMock()
    mock_speaker_mgr.on_speaking_start = AsyncMock(return_value=True)

    receiver = AudioReceiver(mock_vc, mock_speaker_mgr)

    latency_tracker.start("concurrent_users")

    with patch('asyncio.create_task'):
        # 10 users, each sending 10 packets
        for user_id in range(10):
            mock_user = MagicMock()
            mock_user.id = user_id

            for packet_num in range(10):
                audio_data = {'data': bytes([packet_num]) * 960}
                receiver.write(audio_data, mock_user)

    latency = latency_tracker.end("concurrent_users")

    print(f"\nüéØ 10 users, 100 total packets in {latency:.2f}ms")
    print(f"   Average per packet: {latency/100:.2f}ms")

    # Verify all users buffered
    assert len(receiver.user_buffers) == 10
    for user_id in range(10):
        assert str(user_id) in receiver.user_buffers
        assert receiver.user_buffers[str(user_id)].qsize() == 10

    print(f"\n‚úÖ Concurrent users validated: {len(receiver.user_buffers)} buffers")
