services:
  # PostgreSQL - Database for agents, sessions, conversations
  # Using pgvector/pgvector image for pgvector extension support (memory system)
  postgres:
    image: pgvector/pgvector:pg15
    container_name: voxbridge-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-voxbridge}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-voxbridge_dev_password}
      - POSTGRES_DB=${POSTGRES_DB:-voxbridge}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - bot-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-voxbridge}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # WhisperX STT Server - Handles speech-to-text with GPU
  whisperx:
    build:
      context: .
      dockerfile: Dockerfile.whisperx
    container_name: voxbridge-whisperx
    security_opt:
      - seccomp:unconfined
    ports:
      - "4901:4901"  # WebSocket
      - "4902:4902"  # Health check
    volumes:
      - ./src/whisper_server.py:/app/src/whisper_server.py  # Live code updates
      - ./requirements.txt:/app/requirements.txt             # For reference
      - whisperx-models:/root/.cache/whisperx                # Cache downloaded models
    environment:
      - WHISPERX_MODEL=${WHISPERX_MODEL:-small}
      - WHISPERX_DEVICE=${WHISPERX_DEVICE:-auto}
      - WHISPERX_COMPUTE_TYPE=${WHISPERX_COMPUTE_TYPE:-float16}
      - WHISPERX_BATCH_SIZE=${WHISPERX_BATCH_SIZE:-16}
      - WHISPERX_VAD_ONSET=${WHISPERX_VAD_ONSET:-0.600}
      - WHISPERX_VAD_OFFSET=${WHISPERX_VAD_OFFSET:-0.450}
      - WHISPER_SERVER_PORT=4901
    restart: unless-stopped
    networks:
      - bot-network
      - pinkleberry_bridge
    # GPU support - Use GPU 1 only
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]

  # VoxBridge Discord - Python Discord voice bridge (STT/TTS)
  voxbridge-api:
    build:
      context: .
      dockerfile: Dockerfile.python
    container_name: voxbridge-api
    ports:
      - "4900:4900"
    volumes:
      - ./src:/app/src                                            # Mount entire src directory for live updates
      - ./requirements-bot.txt:/app/requirements-bot.txt          # For reference
      - ./assets:/app/assets                                      # Thinking indicator sound effects
      - voxbridge-models:/home/appuser/.cache/huggingface         # Cache for ML models (embeddings, etc.)
    environment:
      # Discord
      - DISCORD_TOKEN=${DISCORD_TOKEN}
      - USE_LEGACY_DISCORD_BOT=${USE_LEGACY_DISCORD_BOT:-false}

      # WhisperX Configuration - Connect to whisperx container
      - WHISPER_SERVER_URL=ws://whisperx:4901

      # Speaker Management
      - SILENCE_THRESHOLD_MS=${SILENCE_THRESHOLD_MS:-600}
      - MAX_SPEAKING_TIME_MS=${MAX_SPEAKING_TIME_MS:-45000}

      # Chatterbox TTS
      - CHATTERBOX_URL=http://chatterbox-tts:4123
      - CHATTERBOX_VOICE_ID=${CHATTERBOX_VOICE_ID}

      # n8n Integration
      - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL}
      - N8N_WEBHOOK_TEST_URL=${N8N_WEBHOOK_TEST_URL}
      - N8N_TEST_MODE=${N8N_TEST_MODE:-false}

      # Streaming Configuration
      - USE_STREAMING=${USE_STREAMING:-true}

      # Streaming Configuration (Response Chunking + TTS)
      - STREAMING_ENABLED=${STREAMING_ENABLED:-true}
      - STREAMING_CHUNKING_STRATEGY=${STREAMING_CHUNKING_STRATEGY:-sentence}
      - STREAMING_MIN_CHUNK_LENGTH=${STREAMING_MIN_CHUNK_LENGTH:-10}
      - STREAMING_MAX_CONCURRENT_TTS=${STREAMING_MAX_CONCURRENT_TTS:-3}
      - STREAMING_ERROR_STRATEGY=${STREAMING_ERROR_STRATEGY:-retry}
      - STREAMING_INTERRUPTION_STRATEGY=${STREAMING_INTERRUPTION_STRATEGY:-graceful}

      # Latency Optimization Features
      - USE_CLAUSE_SPLITTING=${USE_CLAUSE_SPLITTING:-true}
      - USE_PARALLEL_TTS=${USE_PARALLEL_TTS:-false}
      - USE_PROGRESSIVE_TTS_PLAYBACK=${USE_PROGRESSIVE_TTS_PLAYBACK:-false}
      - USE_THINKING_INDICATORS=${USE_THINKING_INDICATORS:-true}
      - THINKING_INDICATOR_PROBABILITY=${THINKING_INDICATOR_PROBABILITY:-0.8}
      - MIN_CLAUSE_LENGTH=${MIN_CLAUSE_LENGTH:-10}
      - MIN_SENTENCE_LENGTH=${MIN_SENTENCE_LENGTH:-3}
      - DISCORD_AUDIO_QUEUE_SIZE=${DISCORD_AUDIO_QUEUE_SIZE:-100}

      # Server Config
      - PORT=4900

      # Database Configuration
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-voxbridge}:${POSTGRES_PASSWORD:-voxbridge_dev_password}@postgres:5432/${POSTGRES_DB:-voxbridge}

      # LLM Provider Configuration (VoxBridge 2.0 Phase 3)
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - LOCAL_LLM_BASE_URL=${LOCAL_LLM_BASE_URL}
      - LOCAL_LLM_RELEVANCE_MODEL=${LOCAL_LLM_RELEVANCE_MODEL:-gemma3n:latest}

      # Plugin System Security (VoxBridge 2.0 Phase 6)
      - PLUGIN_ENCRYPTION_KEY=${PLUGIN_ENCRYPTION_KEY}

      # Memory System - Model Cache (VoxBridge 2.0 Phase 2)
      - HF_HOME=/home/appuser/.cache/huggingface               # HuggingFace cache location for embedding models
    depends_on:
      postgres:
        condition: service_healthy
      whisperx:
        condition: service_started
    restart: unless-stopped
    networks:
      - bot-network
      - pinkleberry_bridge

  # VoxBridge Frontend - React monitoring dashboard
  voxbridge-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_URL=http://localhost:4900
        - VITE_WS_URL=ws://localhost:4900
    container_name: voxbridge-frontend
    ports:
      - "${FRONTEND_PORT:-4903}:80"
    depends_on:
      - voxbridge-api
    restart: unless-stopped
    networks:
      - bot-network
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      start_period: 10s
      retries: 3

networks:
  bot-network:
    external: true
  pinkleberry_bridge:
    external: true

volumes:
  whisperx-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../zexternal-volumes/voxbridge-whisperx-models
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../zexternal-volumes/voxbridge-postgres-data
  voxbridge-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../zexternal-volumes/voxbridge-models
